# Actividad 4 ‚Äì ML2: Redes Neuronales para Predicci√≥n de Churn (Telco)

Repositorio correspondiente a la **Actividad 4 de Machine Learning II**, donde se implementan y comparan modelos de **Deep Learning (MLP y CNN 1D)** sobre el dataset **Telco Churn**, manteniendo el esquema base de preprocesamiento (imputaci√≥n, one-hot encoding y escalamiento).

---

## üéØ Objetivo

Predecir la probabilidad de que un cliente realice **Churn** (abandono del servicio), formulado como un problema de **clasificaci√≥n binaria desbalanceada**, evaluando el aporte de redes neuronales frente a modelos cl√°sicos desde una perspectiva **t√©cnica y de negocio**.

---

## üì¶ Dataset

- **Fuente:** `data/data-churn.csv`
- **Observaciones:** ~7.043 clientes
- **Variable objetivo:** `Churn` (Yes / No ‚Üí 1 / 0)
- **Proporci√≥n clase positiva (churn):** ~26.5%

Cada fila representa un cliente con variables demogr√°ficas, contractuales, de servicios y facturaci√≥n.

---

## ‚öôÔ∏è Preprocesamiento (esquema base solicitado)

Se mantuvo el esquema est√°ndar solicitado en el curso para asegurar comparabilidad:

- **Variables num√©ricas**
  - Imputaci√≥n por mediana
  - Escalamiento con `StandardScaler`

- **Variables categ√≥ricas**
  - Imputaci√≥n por moda
  - One-Hot Encoding con `handle_unknown="ignore"`

- **Split:** Train/Test estratificado (80/20)
- **M√©trica principal:** **F1-score sobre la clase positiva (churn = 1)**

---

# ‚úÖ Paso 1 ‚Äî MLP (Perceptr√≥n Multi-Capa)

## Arquitectura del modelo

- Capa densa: `Dense(64, ReLU)` + Dropout
- Capa densa: `Dense(32, ReLU)` + Dropout
- Capa de salida: `Dense(1, Sigmoid)`

**Funci√≥n de p√©rdida:** Binary Crossentropy  
**Optimizador:** Adam  

Esta arquitectura balancea **capacidad de representaci√≥n** y **riesgo de sobreajuste** para un dataset tabular de tama√±o medio.

---

## üìà Curvas de entrenamiento ‚Äî MLP

### Loss
![MLP Loss](figures/mlp_loss.png)

### AUC
![MLP AUC](figures/mlp_auc.png)

**Observaci√≥n:**  
La p√©rdida de entrenamiento disminuye consistentemente, mientras que la validaci√≥n se estabiliza, indicando convergencia con leve sobreajuste controlado.

---

## üìä Resultados en Test ‚Äî MLP

- **Accuracy:** 0.7807  
- **Precision:** 0.5910  
- **Recall:** 0.5642  
- **F1:** 0.5773  
- **ROC-AUC:** 0.8366  
- **PR-AUC:** 0.6345  

### Matriz de Confusi√≥n
![MLP CM](figures/mlp_cm.png)

### Curva ROC
![MLP ROC](figures/mlp_roc.png)

### Curva Precision‚ÄìRecall
![MLP PR](figures/mlp_pr.png)

**Interpretaci√≥n:**  
El modelo logra un equilibrio razonable entre precision y recall, adecuado para escenarios de retenci√≥n donde es preferible capturar churn reales.

---

# ‚úÖ Paso 2 ‚Äî Experimentos: Learning Rate y Batch Size

Se analizaron los efectos de:

- **Learning Rate:** estabilidad de la convergencia
- **Batch Size (16 / 32 / 64):** velocidad de entrenamiento vs generalizaci√≥n

**Conclusi√≥n:**  
Learning rates peque√±os favorecen estabilidad, mientras que batch sizes intermedios (32) logran un buen compromiso entre tiempo y desempe√±o.

---

# ‚úÖ Paso 3 ‚Äî Red Neuronal Convolucional (CNN 1D)

## Justificaci√≥n

Aunque el churn es un problema tabular, se reinterpretan las features como una **se√±al 1D**, permitiendo a la CNN detectar **patrones locales entre grupos de variables** mediante filtros convolucionales.

---

## Arquitectura CNN 1D

- Conv1D + MaxPooling
- Conv1D + GlobalMaxPooling
- Capa densa final + Sigmoid

---

## üìà Curvas de entrenamiento ‚Äî CNN

### Loss
![CNN Loss](figures/cnn_loss2.png)

---

## üìä Resultados en Test ‚Äî CNN 1D

- **Accuracy:** 0.7956  
- **Precision:** 0.6453  
- **Recall:** 0.5107  
- **F1:** 0.5701  
- **ROC-AUC:** 0.8387  
- **PR-AUC:** 0.6323  

### Matriz de Confusi√≥n
![CNN CM](figures/cnn_cm2.png)

### Curva ROC
![CNN ROC](figures/cnn_roc2.png)

### Curva Precision‚ÄìRecall
![CNN PR](figures/cnn_pr2.png)

**Interpretaci√≥n:**  
La CNN mejora la precision pero reduce el recall, lo que puede ser menos conveniente en estrategias de retenci√≥n donde el costo de no detectar churn es alto.

---

# ‚úÖ Paso 4 ‚Äî Comparaci√≥n final y an√°lisis cr√≠tico

| Modelo | Accuracy | Precision | Recall | F1 | ROC-AUC | PR-AUC |
|------|---------:|----------:|-------:|---:|--------:|-------:|
| MLP | 0.7807 | 0.5910 | 0.5642 | **0.5773** | 0.8366 | **0.6345** |
| CNN 1D | 0.7956 | **0.6453** | 0.5107 | 0.5701 | **0.8387** | 0.6323 |

---

## üß† An√°lisis desde la perspectiva de negocio

- El **MLP ofrece mejor balance Recall/F1**, clave para retenci√≥n de clientes.
- La **CNN no aporta una mejora significativa** frente a su mayor complejidad.
- En datasets tabulares medianos, **modelos cl√°sicos o MLP simples son suficientes**.
- Las redes neuronales aportan ventajas claras solo con:
  - Mayor volumen de datos
  - Estructura temporal o espacial
  - Interacciones no lineales complejas

---

## ‚ö†Ô∏è Riesgos de sobreajuste

- Arquitecturas profundas con pocos datos
- Exceso de par√°metros sin regularizaci√≥n
- Optimizaci√≥n basada solo en accuracy

Se mitiga mediante Dropout, validaci√≥n y m√©tricas orientadas a la clase minoritaria.

---

## üßæ Reproducibilidad

Instalaci√≥n de dependencias:

```bash
pip install -r requirements.txt
