# Actividad 4 ‚Äì ML2: Redes Neuronales para Predicci√≥n de Churn (Telco)

Repositorio correspondiente a la **Actividad 4 de Machine Learning II**, donde se implementan y comparan modelos de Deep Learning (MLP y CNN 1D) sobre el dataset **Telco Churn**, manteniendo el esquema base de preprocesamiento (imputaci√≥n, one-hot encoding y escalamiento).

---

## üéØ Objetivo

Predecir la probabilidad de que un cliente realice **Churn** (abandono del servicio), formulado como un problema de **clasificaci√≥n binaria desbalanceada**.

---

## üì¶ Dataset

- Fuente: `data/data-churn.csv`
- Observaciones: ~7.043 clientes
- Target: `Churn` (Yes/No ‚Üí 1/0)
- Proporci√≥n clase positiva (churn): ~26.5%

---

## ‚öôÔ∏è Preprocesamiento (Base solicitada)

Se mantuvo el esquema est√°ndar solicitado:

- **Num√©ricas**: imputaci√≥n mediana + `StandardScaler`
- **Categ√≥ricas**: imputaci√≥n por moda + `OneHotEncoder(handle_unknown="ignore")`
- Split train/test estratificado (80/20)
- M√©trica principal: **F1 sobre clase positiva (churn=1)**

---

# ‚úÖ Paso 1 ‚Äî MLP (Perceptr√≥n Multi-Capa)

## Arquitectura

- Dense(64, ReLU) + Dropout
- Dense(32, ReLU) + Dropout
- Dense(1, Sigmoid)

**Loss:** Binary Crossentropy  
**Optimizador:** Adam

## Curvas de entrenamiento
![MLP Loss](figures/mlp_loss.png)
![MLP AUC](figures/mlp_auc.png)

## Resultados en test (MLP)

- Accuracy: 0.7807  
- Precision: 0.5910  
- Recall: 0.5642  
- F1: 0.5773  
- ROC-AUC: 0.8366  
- PR-AUC: 0.6345  

**Gr√°ficos:**
![MLP CM](figures/mlp_cm.png)
![MLP ROC](figures/mlp_roc.png)
![MLP PR](figures/mlp_pr.png)

---

# ‚úÖ Paso 2 ‚Äî Experimentos (Learning Rate y Batch Size)

Se eval√∫a el impacto en convergencia, estabilidad y tiempo de entrenamiento.

### Learning Rate (comparaci√≥n)
(Insertar tabla/resultado del notebook)

### Batch Size (16/32/64)
(Insertar tabla/resultado del notebook)

---

# ‚úÖ Paso 3 ‚Äî CNN 1D

## Justificaci√≥n

Aunque churn es tabular, se reinterpretan features como se√±al 1D para explorar detecci√≥n de patrones locales (kernels + pooling).

## Arquitectura (CNN)

- Conv1D + MaxPooling
- Conv1D + GlobalMaxPooling
- Dense final + Sigmoid

## Curvas y resultados (CNN)

![CNN Loss](figures/cnn_loss.png)
![CNN AUC](figures/cnn_auc.png)

**Resultados en test (CNN 1D):**
- Accuracy: 0.7956  
- Precision: 0.6453  
- Recall: 0.5107  
- F1: 0.5701  
- ROC-AUC: 0.8387  
- PR-AUC: 0.6323  

**Gr√°ficos:**
![CNN CM](figures/cnn_cm.png)
![CNN ROC](figures/cnn_roc.png)
![CNN PR](figures/cnn_pr.png)

---

# ‚úÖ Paso 4 ‚Äî Comparaci√≥n final y an√°lisis cr√≠tico

| Modelo | Accuracy | Precision | Recall | F1 | ROC-AUC | PR-AUC |
|---|---:|---:|---:|---:|---:|---:|
| MLP | 0.7807 | 0.5910 | 0.5642 | 0.5773 | 0.8366 | 0.6345 |
| CNN 1D | 0.7956 | 0.6453 | 0.5107 | 0.5701 | 0.8387 | 0.6323 |

**Lectura cr√≠tica:**
- MLP ofrece mejor equilibrio (F1/Recall) para un problema de retenci√≥n.
- CNN aumenta precision pero reduce recall, lo que podr√≠a dejar escapar churn reales.
- En dataset tabular moderado, modelos cl√°sicos pueden competir fuertemente con redes.

---

## üßæ Reproducibilidad

Instalaci√≥n:

```bash
pip install -r requirements.txt
